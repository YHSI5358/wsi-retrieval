{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import openslide\n",
    "import os, sys, json, asyncio, aiohttp, requests, logging\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import timm, torch\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "origin_list = []\n",
    "wsi_list = os.listdir('/hpc2hdd/home/ysi538/retrieval/caches/wsi_image')\n",
    "for wsi in wsi_list:\n",
    "    #  _ origin_list\n",
    "    origin_list.append('_'.join(wsi.split('_')[1:]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8341, 8341)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wsi_list), len(origin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('wsi_list.txt', 'w') as f:\n",
    "    f.write('\\n'.join(wsi_list))\n",
    "with open('origin_list.txt', 'w') as f:\n",
    "    f.write('\\n'.join(origin_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_list = os.listdir('/hpc2hdd/home/ysi538/retrieval/MDI_RAG_Image2Image_Research/data/embedding_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for fold in fold_list:\n",
    "    idx = origin_list.index(fold)\n",
    "    os.rename(f'/hpc2hdd/home/ysi538/retrieval/MDI_RAG_Image2Image_Research/data/embedding_cache/{fold}', f'/hpc2hdd/home/ysi538/retrieval/MDI_RAG_Image2Image_Research/data/embedding_cache/{wsi_list[idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWSIDataset(Dataset):\n",
    "    def __init__(self, images, transform):\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "    \n",
    "\n",
    "class WSIUNIEncoder():\n",
    "    def __init__(self, **kwargs):\n",
    "        self.embed_model =  timm.create_model(\n",
    "            \"vit_large_patch16_224\", img_size=224, patch_size=16, init_values=1e-5, num_classes=0, dynamic_img_size=True\n",
    "        )\n",
    "        self.transform = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "\n",
    "        local_dir = \"/hpc2hdd/home/ysi538/retrieval/checkpoints/vit_large_patch16_224.dinov2.uni_mass100k/\"\n",
    "        self._device = self.infer_torch_device()\n",
    "        print(self._device)\n",
    "        self.embed_model.load_state_dict(torch.load(os.path.join(local_dir, \"pytorch_model.bin\"), map_location=\"cpu\"), strict=True)\n",
    "        self.embed_model = self.embed_model.to(self._device)\n",
    "        self.embed_model.eval()\n",
    "\n",
    "    def infer_torch_device(self):\n",
    "        \"\"\"Infer the input to torch.device.\"\"\"\n",
    "        try:\n",
    "            has_cuda = torch.cuda.is_available()\n",
    "        except NameError:\n",
    "            import torch  # pants: no-infer-dep\n",
    "            has_cuda = torch.cuda.is_available()\n",
    "        if has_cuda:\n",
    "            return \"cuda\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            return \"mps\"\n",
    "        return \"cpu\"\n",
    "\n",
    "    def encode_wsi_patch(self, wsi_name, dataloader):\n",
    "        embeddings = []\n",
    "        with torch.no_grad():\n",
    "            for images in tqdm(dataloader, desc=f\"WSI name: {wsi_name}\", ascii=True):\n",
    "                images = images.to(self._device)\n",
    "                embedding = self.embed_model(images)\n",
    "                embeddings.append(embedding.cpu())\n",
    "\n",
    "        if embeddings == []:\n",
    "            return []\n",
    "        else:\n",
    "            patch_embeddings = torch.cat(embeddings, dim=0).cpu().tolist()\n",
    "            return patch_embeddings\n",
    "\n",
    "class Embedding_loader():\n",
    "    def __init__(self):\n",
    "        self.wsi_patch_encoder = WSIUNIEncoder()\n",
    "        self.cache_path = \"/hpc2hdd/home/ysi538/retrieval/MDI_RAG_Image2Image_Research/data/embedding_cache\"\n",
    "        self.loaded_embeddings = os.listdir(self.cache_path)\n",
    "\n",
    "    async def load_images(self, images):\n",
    "        \"\"\" \"\"\"\n",
    "        return images\n",
    "\n",
    "    async def loading_wsi_image(self, wsi_name, images):\n",
    "        \"\"\"  CPU   WSI patch   Dataloader \"\"\"\n",
    "        patch_infos = [f\"patch_{i}\" for i in range(len(images))]\n",
    "        images = await self.load_images(images)\n",
    "\n",
    "        wsi_dataset = CustomWSIDataset(images, self.wsi_patch_encoder.transform)\n",
    "        dataloader = DataLoader(wsi_dataset, batch_size=16, shuffle=False, num_workers=16, pin_memory=True)\n",
    "\n",
    "        return patch_infos, dataloader\n",
    "\n",
    "    def loading_worker(self, input_queue, output_queue):\n",
    "        while True:\n",
    "            item = input_queue.get()\n",
    "            if item is None:\n",
    "                break\n",
    "\n",
    "            wsi_name, images = item\n",
    "            if wsi_name in self.loaded_embeddings:\n",
    "                print(f\"WSI {wsi_name} cached.\")\n",
    "                output_queue.put((wsi_name, [], []))\n",
    "            else:\n",
    "                patch_infos, dataloader = asyncio.run(self.loading_wsi_image(wsi_name, images))\n",
    "                output_queue.put((wsi_name, patch_infos, dataloader))\n",
    "    \n",
    "    def encoding_worker(self, input_queue):\n",
    "        while True:\n",
    "            item = input_queue.get()\n",
    "            if item is None:\n",
    "                break\n",
    "\n",
    "            wsi_name, patch_infos, dataloader = item\n",
    "            patch_embeddings = self.wsi_patch_encoder.encode_wsi_patch(wsi_name, dataloader)\n",
    "\n",
    "            dir_path = os.path.join(self.cache_path, wsi_name)\n",
    "            if not os.path.exists(dir_path):\n",
    "                os.makedirs(dir_path)\n",
    "\n",
    "            info_path = os.path.join(self.cache_path, wsi_name, \"patch_info.json\")\n",
    "            with open(info_path, 'w') as file:\n",
    "                json.dump(patch_infos, file)\n",
    "\n",
    "            embedding_path = os.path.join(self.cache_path, wsi_name, \"embeddings.json\")\n",
    "            with open(embedding_path, 'w') as file:\n",
    "                json.dump(patch_embeddings, file)\n",
    "    \n",
    "    def main(self, wsi_data_list):\n",
    "        load_workers = 2\n",
    "        load_queue = mp.Queue(maxsize=8)\n",
    "        encode_queue = mp.Queue(maxsize=8)\n",
    "\n",
    "        loading_processes = [mp.Process(target=self.loading_worker, args=(load_queue, encode_queue)) for _ in range(load_workers)]\n",
    "        encoding_process = mp.Process(target=self.encoding_worker, args=(encode_queue,))\n",
    "\n",
    "        for p in loading_processes:\n",
    "            p.start()\n",
    "        encoding_process.start()\n",
    "\n",
    "        for wsi_name, images in wsi_data_list:\n",
    "            load_queue.put((wsi_name, images))\n",
    "\n",
    "        for _ in range(load_workers):\n",
    "            load_queue.put(None)\n",
    "        for p in loading_processes:\n",
    "            p.join()\n",
    "\n",
    "        encode_queue.put(None)\n",
    "        encoding_process.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_region_with_rotate(slide, x, y, level, w, h, angle = 0):\n",
    "\n",
    "    center_x, center_y = x + w / 2, y + h / 2\n",
    "\n",
    "    radians = np.deg2rad(angle)\n",
    "    cos_r = abs(np.cos(radians))\n",
    "    sin_r = abs(np.sin(radians))\n",
    "    new_w = w * cos_r + h * sin_r\n",
    "    new_h = w * sin_r + h * cos_r\n",
    "\n",
    "    new_w = int(np.ceil(new_w))\n",
    "    new_h = int(np.ceil(new_h))\n",
    "\n",
    "    new_x = int(center_x - new_w / 2)\n",
    "    new_y = int(center_y - new_h / 2)\n",
    "\n",
    "\n",
    "    region = slide.read_region((new_x, new_y), level, (new_w, new_h))\n",
    "    region = region.rotate(angle, expand=True)\n",
    "\n",
    "    region_center_x, region_center_y = region.size[0] / 2, region.size[1] / 2\n",
    "    region_x = int(region_center_x - w / 2)\n",
    "    region_y = int(region_center_y - h / 2)\n",
    "    region_w = w\n",
    "    region_h = h\n",
    "    region = region.crop((region_x, region_y, region_x + region_w, region_y + region_h))\n",
    "\n",
    "    return region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def file_md5(fileName):\n",
    "    m = hashlib.md5()\n",
    "    blocksize = 2**20\n",
    "    with open(fileName, \"rb\") as f:\n",
    "        while True:\n",
    "            buf = f.read(blocksize)\n",
    "            if not buf:\n",
    "                break\n",
    "            m.update(buf)\n",
    "    return m.hexdigest()\n",
    "\n",
    "def get_slide_info(wsi_name):\n",
    "    metadata = {}\n",
    "    filepath = os.path.join('caches/wsi_image/', wsi_name)\n",
    "    filepath = os.path.join('/hpc2hdd/home/ysi538/retrieval/caches/wsi_image/', wsi_name)\n",
    "    if not os.path.isfile(filepath):\n",
    "        msg = {\"error\": \"No such file\"}\n",
    "        print(msg)\n",
    "        return msg\n",
    "    # metadata['location'] = filepath\n",
    "    print(f\"Loading {filepath}\")\n",
    "    try:\n",
    "        slide = openslide.OpenSlide(filepath)\n",
    "    except BaseException as error:\n",
    "        msg = {\"type\": \"Openslide\", \"error\": str(error)}\n",
    "        print(msg)\n",
    "        return msg\n",
    "    slide_properties = slide.properties\n",
    "    return slide, slide_properties\n",
    "\n",
    "\n",
    "def loading_wsi(wsi_name):\n",
    "    slice_size = (256, 256)\n",
    "    slide, slide_info = get_slide_info(wsi_name)\n",
    "    print(slide_info)\n",
    "    num_level = int(slide_info.get('openslide.level-count', 1))\n",
    "    patch_info_list = []\n",
    "    for level in range(1, num_level):       # start from level 1\n",
    "\n",
    "        width = int(slide_info.get(f\"openslide.level[{level}].width\"))\n",
    "        height = int(slide_info.get(f\"openslide.level[{level}].height\"))\n",
    "\n",
    "        for y in range(0, height, slice_size[1]):\n",
    "            for x in range(0, width, slice_size[0]):\n",
    "                patch_infos = {\n",
    "                    \"x\": str(x),\n",
    "                    \"y\": str(y),\n",
    "                    \"width\": str(slice_size[1]),\n",
    "                    \"height\": str(slice_size[0]),\n",
    "                    \"level\": str(level)\n",
    "                }\n",
    "                patch_info_list.append(patch_infos)\n",
    "\n",
    "    captions = []\n",
    "    regions = []\n",
    "    for patch_info in tqdm(patch_info_list):\n",
    "        x, y, width, height, level = int(patch_info[\"x\"]), int(patch_info[\"y\"]), int(patch_info[\"width\"]), int(patch_info[\"height\"]), int(patch_info[\"level\"])\n",
    "        region = slide.read_region((x, y), level, (width, height))\n",
    "        regions.append(region)\n",
    "        captions.append(wsi_name + f\"_{x}_{y}_{width}_{height}_{level}.png\")\n",
    "        \n",
    "    return regions, captions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "file_path = \"/hpc2hdd/home/ysi538/retrieval/MDI_RAG_Image2Image_Research/data/wsi_names.json\"\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        wsi_name_list = json.load(f)\n",
    "        for wsi_name in wsi_name_list:\n",
    "            regions, captions  = loading_wsi(wsi_name)\n",
    "            #  region encode\n",
    "            wsi_data_list = [(wsi_name, regions)]\n",
    "            emb_loader = Embedding_loader()\n",
    "            emb_loader.main(wsi_data_list)\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_img_path =  \n",
    "query_img_path =  \n",
    "response = requests.get(query_img_path)\n",
    "img = response.content\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yhre-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
