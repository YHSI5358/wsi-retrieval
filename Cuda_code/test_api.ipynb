{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import numpy as np \n",
    "import cupy as cp\n",
    "import sys\n",
    "from cuvs.neighbors import hnsw,cagra\n",
    "import os\n",
    "import time\n",
    "sys.path.append('/hpc2hdd/home/ysi538/retrieval')\n",
    "from MDI_RAG_Image2Image_Research.src.utils.encoder import WSI_Image_UNI_Encoder\n",
    "\n",
    "# url = '  /hpc/retrieval/query/image2image_retrieval'\n",
    "url = 'http://localhost:9876/test'\n",
    "query_img_path = \" metaservice/api/region/openslide/241183-21.tiff/6400/25344/256/256/1\"\n",
    "request_data = {\n",
    "    'query_img_path': query_img_path,\n",
    "    'top_k': 20\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=request_data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    response_data = response.json()\n",
    "    print(\"Response JSON:\", response_data)\n",
    "else:\n",
    "    print(\"Request failed with status code:\", response.status_code) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_regions(result_infos):\n",
    "\n",
    "    search_info_list = []\n",
    "    \n",
    "    for info in result_infos:\n",
    "        search_info = {}\n",
    "        level = info.split(\"_\")[-1].split(\".\")[0]\n",
    "        w = info.split(\"_\")[-3]\n",
    "        h = info.split(\"_\")[-2]\n",
    "        x = info.split(\"_\")[-5]\n",
    "        y = info.split(\"_\")[-4]\n",
    "        id = info.split(\"_\")[0]\n",
    "        name = \"_\".join(info.split(\"_\")[1:-5])\n",
    "        search_info = {\"id\": id, \"name\": name, \"x\": x, \"y\": y, \"w\": w, \"h\": h, \"level\": level}\n",
    "        search_info_list.append(search_info)\n",
    "\n",
    "    def dfs(node, component, visited):\n",
    "        \n",
    "        visited[node] = True\n",
    "        \n",
    "        component.append(search_info_list[node])\n",
    "        \n",
    "        \n",
    "        for neighbor in range(len(search_info_list)):\n",
    "            if not visited[neighbor] and judge_if_connected(search_info_list[node], search_info_list[neighbor]):\n",
    "                \n",
    "                dfs(neighbor, component, visited)\n",
    "\n",
    "    \n",
    "    visited = [False] * len(search_info_list)\n",
    "    components = []\n",
    "\n",
    "    \n",
    "    for i in range(len(search_info_list)):\n",
    "        if not visited[i]:\n",
    "            \n",
    "            current_component = []\n",
    "            \n",
    "            dfs(i, current_component, visited)\n",
    "            \n",
    "            components.append(current_component)\n",
    "\n",
    "    \n",
    "    components = [component for component in components if len(component) > 1]\n",
    "\n",
    "    return components\n",
    "\n",
    "def judge_if_connected(info1, info2):\n",
    "    \n",
    "    if info1[\"name\"] != info2[\"name\"]:\n",
    "        return False\n",
    "    if info1[\"level\"] != info2[\"level\"]:\n",
    "        return False\n",
    "    if int(info1[\"x\"]) + int(info1[\"w\"]) == int(info2[\"x\"]) and int(info1[\"y\"]) == int(info2[\"y\"]):\n",
    "        return True\n",
    "    if int(info1[\"x\"]) - int(info1[\"w\"]) == int(info2[\"x\"]) and int(info1[\"y\"]) == int(info2[\"y\"]):\n",
    "        return True\n",
    "    if int(info1[\"y\"]) + int(info1[\"h\"]) == int(info2[\"y\"]) and int(info1[\"x\"]) == int(info2[\"x\"]):\n",
    "        return True\n",
    "    if int(info1[\"y\"]) - int(info1[\"h\"]) == int(info2[\"y\"]) and int(info1[\"x\"]) == int(info2[\"x\"]):\n",
    "        return True\n",
    "    if int(info1[\"x\"]) + int(info1[\"w\"]) == int(info2[\"x\"]) and int(info1[\"y\"]) + int(info1[\"h\"]) == int(info2[\"y\"]):\n",
    "        return True\n",
    "    if int(info1[\"x\"]) - int(info1[\"w\"]) == int(info2[\"x\"]) and int(info1[\"y\"]) - int(info1[\"h\"]) == int(info2[\"y\"]):\n",
    "        return True\n",
    "    if int(info1[\"x\"]) + int(info1[\"w\"]) == int(info2[\"x\"]) and int(info1[\"y\"]) - int(info1[\"h\"]) == int(info2[\"y\"]):\n",
    "        return True\n",
    "    if int(info1[\"x\"]) - int(info1[\"w\"]) == int(info2[\"x\"]) and int(info1[\"y\"]) + int(info1[\"h\"]) == int(info2[\"y\"]):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def request_image(query_img_path):\n",
    "    if \"http\" in query_img_path:\n",
    "        response = requests.get(query_img_path, verify=False)\n",
    "        query_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "    else:\n",
    "        query_image = Image.open(query_img_path).convert(\"RGB\")\n",
    "    return query_image\n",
    "\n",
    "def split_img(query_image, other_info):\n",
    "    imgs = []\n",
    "    \n",
    "    w, h = query_image.size\n",
    "    if w == h:\n",
    "        return [query_image]\n",
    "    if w > h:\n",
    "        new_w = h\n",
    "        new_h = h\n",
    "    else:\n",
    "        new_w = w\n",
    "        new_h = w\n",
    "    for i in range(0, w, new_w):\n",
    "        for j in range(0, h, new_h):\n",
    "            box = (i, j, i + new_w, j + new_h)\n",
    "            img = query_image.crop(box)\n",
    "            imgs.append(img)\n",
    "    return imgs\n",
    "\n",
    "def get_img_other_info(query_path):\n",
    "    pass\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_index_file(index_file):\n",
    "        index = hnsw.load(index_file, 1024, np.float32, \"sqeuclidean\")\n",
    "        return index\n",
    "\n",
    "def load_info_file(info_file):\n",
    "    with open (info_file, 'r') as f:\n",
    "        infos = json.load(f)\n",
    "    return infos\n",
    "\n",
    "\n",
    "\n",
    "def search(index, encoder, infos_list, query_path, top_k=20):\n",
    "    total_neighbors = []\n",
    "    total_distances = []\n",
    "    query_image = request_image(query_path)\n",
    "    \n",
    "    img_other_info = get_img_other_info(query_path)\n",
    "    split_imgs = split_img(query_image, img_other_info)\n",
    "    \n",
    "    split_embeddings = cp.array([cp.array(encoder.encode_image(after_split_img)).astype('float32') for after_split_img in split_imgs])\n",
    "    \n",
    "    \n",
    "    if split_embeddings.ndim == 1:\n",
    "        split_embeddings = split_embeddings.reshape(1, -1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    result_infos = []\n",
    "    \n",
    "    \n",
    "    time_cost = 0\n",
    "    begin_time = time.time()\n",
    "    \n",
    "    distances, neighbors = cagra.search(cagra.SearchParams(),index, split_embeddings, top_k)\n",
    "    end_time = time.time()\n",
    "    time_cost += end_time - begin_time\n",
    "    \n",
    "    neighbors = cp.asarray(neighbors).flatten().tolist()\n",
    "    distances = cp.asarray(distances).flatten().tolist()\n",
    "    for neighbor in neighbors:\n",
    "        result_infos.append(infos_list[neighbor])\n",
    "    total_neighbors.extend(neighbors)\n",
    "    total_distances.extend(distances)\n",
    "\n",
    "    total_distances, total_neighbors, result_infos = zip(*sorted(zip(total_distances, total_neighbors, result_infos)))\n",
    "    return total_distances[:], total_neighbors[:], result_infos[:]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "query_img_path = \" metaservice/api/region/openslide/241183-21.tiff/6400/25344/512/256/1\"\n",
    "image_encoder = WSI_Image_UNI_Encoder()\n",
    "\n",
    "ssd_dir = \"/hpc2ssd/JH_DATA/spooler/ysi538/\"\n",
    "\n",
    "hnsw_index = load_index_file(ssd_dir + \"cupy_index_batch_0.bin\")\n",
    "infos_list = load_info_file(ssd_dir + \"cupy_infos_batch_0.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] [15:53:42.278367] optimizing graph\n",
      "[I] [15:54:07.391248] Graph optimized, creating index\n"
     ]
    }
   ],
   "source": [
    "embeddings = cp.load(ssd_dir + \"cupy_embeddings_batch_0.npy\")\n",
    "\n",
    "embeddings = cp.asnumpy(embeddings).astype(np.float32)\n",
    "embeddings = cp.array(embeddings, dtype=cp.float32)\n",
    "build_params = cagra.IndexParams(metric=\"sqeuclidean\",build_algo = 'nn_descent')\n",
    "cuda_index = cagra.build(build_params, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc2hdd/home/ysi538/miniconda3/envs/yhre-new/lib/python3.10/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'mdi.hkust-gz.edu.cn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "total_distances, total_neighbors, result_infos = search(cuda_index, image_encoder, infos_list, query_img_path, 20)\n",
    "\n",
    "\n",
    "\n",
    "combined_regions = get_combined_regions(result_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_distances, total_neighbors, result_infos \n",
    "combined_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yhre-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
