{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from cuvs.neighbors import hnsw,cagra\n",
    "import cupy as cp\n",
    "\n",
    "\n",
    "def get_all_folders(path):\n",
    "    all_folders = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if len(dirs) == 0:\n",
    "            all_folders.append(root)\n",
    "    return all_folders\n",
    "\n",
    "root_path = '/hpc2hdd/home/ysi538/my_cuda_code/TCGA_slide_retrieval/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_sites = os.listdir(os.path.join(root_path, 'embed_cache'))\n",
    "site_folders = []\n",
    "for site in all_sites[:]:\n",
    "    total_embeddings = []\n",
    "    total_patch_info = []\n",
    "    # print(site)\n",
    "    site_path = os.path.join(root_path, 'embed_cache', site)\n",
    "    site_folders = os.listdir(site_path)\n",
    "    site_folders = [os.path.join(site_path, folder) for folder in site_folders]\n",
    "\n",
    "    for folder in tqdm(site_folders):\n",
    "        if os.path.isdir(folder):\n",
    "            embeddings = torch.load(os.path.join(folder, 'embeddings')).to('cpu').numpy()\n",
    "            patch_info = json.load(open(os.path.join(folder, 'patch_info.json')))\n",
    "\n",
    "            total_embeddings.append(embeddings)\n",
    "            total_patch_info.append(patch_info)\n",
    "            \n",
    "\n",
    "\n",
    "    total_embeddings = np.concatenate(total_embeddings, axis=0)\n",
    "    total_patch_info = [item for sublist in total_patch_info for item in sublist]\n",
    "\n",
    "    save_path = os.path.join(root_path, \"total_for_site\", site)\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    np.save(os.path.join(save_path, 'total_embeddings.npy'), total_embeddings)\n",
    "    with open(os.path.join(save_path, 'total_patch_info.json'), 'w') as f:\n",
    "        json.dump(total_patch_info, f)\n",
    "    print(f\"Saved {site} total embeddings and patch info to {save_path}\")\n",
    "        \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_site = os.listdir(os.path.join(root_path, \"total_for_site\"))\n",
    "total_site = [os.path.join(root_path, \"total_for_site\", site) for site in total_site]\n",
    "for site in tqdm(total_site):\n",
    "\n",
    "    total_embeddings = np.load(os.path.join(site, 'total_embeddings.npy'))\n",
    "\n",
    "    with open(os.path.join(site, 'total_patch_info.json'), 'r') as f:\n",
    "        total_patch_info = json.load(f)\n",
    "    \n",
    "    print(f\"before total_embeddings shape: {total_embeddings.shape}\")\n",
    "    print(f\"before total_patch_info length: {len(total_patch_info)}\")\n",
    "\n",
    "    foreground_mask = np.array([patch['is_foreground'] for patch in total_patch_info], dtype=bool)\n",
    "    print(f\"foreground_mask shape: {foreground_mask.shape}\")\n",
    "    \n",
    "    total_embeddings = total_embeddings[foreground_mask]\n",
    "    total_patch_info = [patch for patch in total_patch_info if patch['is_foreground'] == 1]\n",
    "\n",
    "    print(f\"after total_embeddings shape: {total_embeddings.shape}\")\n",
    "    print(f\"after total_patch_info length: {len(total_patch_info)}\")\n",
    "    #  \n",
    "    save_path = os.path.join(root_path, \"total_for_site_foreground\", site.split('/')[-1])\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    if os.path.exists(os.path.join(save_path, 'total_embeddings.npy')):\n",
    "        os.remove(os.path.join(save_path, 'total_embeddings.npy'))\n",
    "    np.save(os.path.join(save_path, 'total_embeddings.npy'), total_embeddings)\n",
    "\n",
    "    if os.path.exists(os.path.join(save_path, 'total_patch_info.json')):\n",
    "        os.remove(os.path.join(save_path, 'total_patch_info.json'))\n",
    "    with open(os.path.join(save_path, 'total_patch_info.json'), 'w') as f:\n",
    "        json.dump(total_patch_info, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(total_patch_info[0]['is_foreground'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_site = os.listdir(os.path.join(root_path, \"total_for_site_foreground\"))\n",
    "total_site = [os.path.join(root_path, \"total_for_site_foreground\", site) for site in total_site]\n",
    "for site in tqdm(total_site):\n",
    "\n",
    "    total_embeddings = np.load(os.path.join(site, 'total_embeddings.npy'))\n",
    "\n",
    "    with open(os.path.join(site, 'total_patch_info.json'), 'r') as f:\n",
    "        total_patch_info = json.load(f)\n",
    "\n",
    "    total_embeddings = cp.array(total_embeddings, dtype=cp.float32)\n",
    "\n",
    "\n",
    "    print(f\"site: {site}\")\n",
    "    print(f\"total embeddings shape: {total_embeddings.shape}\")\n",
    "    print(f\"total patch info length: {len(total_patch_info)}\")\n",
    "    \n",
    "    build_params = cagra.IndexParams(metric=\"sqeuclidean\",build_algo = 'nn_descent')\n",
    "    cuda_index = cagra.build(build_params, total_embeddings)\n",
    "\n",
    "    query_embeddings = cp.array(total_embeddings, dtype=cp.float32)\n",
    "    k = 512\n",
    "    distances, neighbors = cagra.search(cagra.SearchParams(itopk_size = k),cuda_index, query_embeddings, k)\n",
    "\n",
    "    result_path = os.path.join(site, 'total_query_results.pkl')\n",
    "    if os.path.exists(result_path):\n",
    "          os.remove(result_path)\n",
    "\n",
    "\n",
    "    with open(os.path.join(site, 'total_query_results.pkl'), 'wb') as f:\n",
    "        pickle.dump((distances, neighbors), f)\n",
    "\n",
    "    del cuda_index\n",
    "    del total_embeddings\n",
    "    del query_embeddings\n",
    "    del distances\n",
    "    del neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors shape: (1778525, 512)\n",
      "distances shape: (1778525, 512)\n",
      "total_patch_info length: 1778525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [30:15<4:32:23, 1816.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site: brain, subtype: LGG, correct: 581514, incorrect: 163314, total: 744828, accuracy: 0.7807359551466916\n",
      "site: brain, subtype: GBM, correct: 871046, incorrect: 162651, total: 1033697, accuracy: 0.8426511830836309\n",
      "neighbors shape: (600261, 512)\n",
      "distances shape: (600261, 512)\n",
      "total_patch_info length: 600261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [41:12<2:31:11, 1133.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site: liver, subtype: CHOL, correct: 12996, incorrect: 28531, total: 41527, accuracy: 0.31295301851807256\n",
      "site: liver, subtype: PAAD, correct: 171193, incorrect: 33109, total: 204302, accuracy: 0.8379408914254388\n",
      "site: liver, subtype: LIHC, correct: 321102, incorrect: 33330, total: 354432, accuracy: 0.9059622156013001\n",
      "neighbors shape: (855157, 512)\n",
      "distances shape: (855157, 512)\n",
      "total_patch_info length: 855157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [57:28<2:03:53, 1061.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site: endocrine, subtype: PCPG, correct: 129947, incorrect: 43721, total: 173668, accuracy: 0.7482495335928323\n",
      "site: endocrine, subtype: THCA, correct: 435138, incorrect: 36015, total: 471153, accuracy: 0.9235598627197534\n",
      "site: endocrine, subtype: ACC, correct: 162967, incorrect: 47369, total: 210336, accuracy: 0.7747936634717785\n",
      "neighbors shape: (1616260, 512)\n",
      "distances shape: (1616260, 512)\n",
      "total_patch_info length: 1616260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [1:09:48<1:33:27, 934.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site: gastrointestinal, subtype: COAD, correct: 392005, incorrect: 236919, total: 628924, accuracy: 0.6232947065146186\n",
      "site: gastrointestinal, subtype: STAD, correct: 433029, incorrect: 196610, total: 629639, accuracy: 0.6877417059616701\n",
      "site: gastrointestinal, subtype: ESCA, correct: 61334, incorrect: 79039, total: 140373, accuracy: 0.43693587798223305\n",
      "site: gastrointestinal, subtype: READ, correct: 46251, incorrect: 171073, total: 217324, accuracy: 0.21282048922346358\n",
      "neighbors shape: (2090337, 512)\n",
      "distances shape: (2090337, 512)\n",
      "total_patch_info length: 2090337\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import cupy as cp\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_map5(query_results, ground_truth, neighbors, total_patch_info):\n",
    "    ap_scores = []\n",
    "    for i in range(len(query_results)):\n",
    "\n",
    "        true_label = ground_truth[i]\n",
    "\n",
    "        neighbor_indices = neighbors[i][:5]\n",
    "\n",
    "        unique_neighbors = []\n",
    "        seen_sub_ids = {total_patch_info[i]['sub_id']} \n",
    "        \n",
    "        for idx in neighbor_indices:\n",
    "            neighbor_idx = int(idx)\n",
    "            patch_info = total_patch_info[neighbor_idx]\n",
    "            if patch_info['sub_id'] not in seen_sub_ids:\n",
    "                seen_sub_ids.add(patch_info['sub_id'])\n",
    "                unique_neighbors.append(patch_info['subtype'])\n",
    "                if len(unique_neighbors) == 5:\n",
    "                    break\n",
    "\n",
    "        if len(unique_neighbors) < 5:\n",
    "            ap_scores.append(0)\n",
    "            continue\n",
    "\n",
    "        ap = 0.0\n",
    "        correct_count = 0\n",
    "        for k in range(5):\n",
    "            if unique_neighbors[k] == true_label:\n",
    "                correct_count += 1\n",
    "                precision_at_k = correct_count / (k + 1)\n",
    "                ap += precision_at_k\n",
    "        \n",
    "        if correct_count > 0:\n",
    "            ap /= min(5, correct_count)\n",
    "        else:\n",
    "            ap = 0\n",
    "        \n",
    "        ap_scores.append(ap)\n",
    "\n",
    "    map5 = sum(ap_scores) / len(ap_scores) if ap_scores else 0\n",
    "    return map5\n",
    "\n",
    "total_site = os.listdir(os.path.join(root_path, \"total_for_site_foreground\"))\n",
    "total_site = [os.path.join(root_path, \"total_for_site_foreground\", site) for site in total_site]\n",
    "dismiss = 0\n",
    "for site in tqdm(total_site[:]):\n",
    "\n",
    "    with open(os.path.join(site, 'total_query_results.pkl'), 'rb') as f:\n",
    "        distances, neighbors = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join(site, 'total_patch_info.json'), 'r') as f:\n",
    "        total_patch_info = json.load(f)\n",
    "\n",
    "    query_results = []\n",
    "    distances = cp.asarray(distances)\n",
    "    neighbors = cp.asarray(neighbors)\n",
    "    \n",
    "    print(f\"neighbors shape: {neighbors.shape}\")\n",
    "    print(f\"distances shape: {distances.shape}\")\n",
    "    print(f\"total_patch_info length: {len(total_patch_info)}\")\n",
    "    \n",
    "\n",
    "    ground_truth = [patch['subtype'] for patch in total_patch_info]\n",
    "    map5 = calculate_map5(query_results, ground_truth, neighbors, total_patch_info)\n",
    "\n",
    "    for i in range(neighbors.shape[0]):\n",
    "        neighbors_patch_info = []\n",
    "        for j in range(neighbors.shape[1]):\n",
    "            neighbor_index = int(neighbors[i][j])\n",
    "            patch_info = total_patch_info[neighbor_index]\n",
    "            if patch_info['sub_id'] != total_patch_info[i]['sub_id']:\n",
    "                neighbors_patch_info.append(patch_info)\n",
    "                if len(neighbors_patch_info) == 5:\n",
    "                    break\n",
    "        \n",
    "        if len(neighbors_patch_info) < 5:\n",
    "            query_results.append(total_patch_info[i]['subtype'])\n",
    "            dismiss += 1\n",
    "        else:\n",
    "            neighbors_labels = [patch['subtype'] for patch in neighbors_patch_info]\n",
    "            label = max(set(neighbors_labels), key=neighbors_labels.count)\n",
    "            query_results.append(label)\n",
    "\n",
    "    correct_count = {subtype: 0 for subtype in set(ground_truth)}\n",
    "    incorrect_count = {subtype: 0 for subtype in set(ground_truth)}\n",
    "    for i in range(len(query_results)):\n",
    "        if query_results[i] == ground_truth[i]:\n",
    "            correct_count[ground_truth[i]] += 1\n",
    "        else:\n",
    "            incorrect_count[ground_truth[i]] += 1\n",
    "    \n",
    "    total_count = {subtype: correct_count[subtype] + incorrect_count[subtype] for subtype in set(ground_truth)}\n",
    "\n",
    "    with open(os.path.join(site, 'total_query_results.json'), 'w') as f:\n",
    "        json.dump({\n",
    "            'correct_count': correct_count, \n",
    "            'incorrect_count': incorrect_count, \n",
    "            'total_count': total_count,\n",
    "            'map5': map5\n",
    "        }, f)\n",
    "\n",
    "    site_name = site.split('/')[-1]\n",
    "    print(f\"\\nSite: {site_name}\")\n",
    "    print(f\"MAP@5: {map5:.4f}\")\n",
    "    \n",
    "    for subtype in set(ground_truth):\n",
    "        if total_count[subtype] != 0:\n",
    "            accuracy = correct_count[subtype] / total_count[subtype]\n",
    "        else:\n",
    "            accuracy = 0\n",
    "        print(f\"Subtype: {subtype}, Correct: {correct_count[subtype]}, Incorrect: {incorrect_count[subtype]}, Total: {total_count[subtype]}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'position': [112, 592], 'subtype': 'LGG', 'level': 'top', 'is_foreground': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " array([  82023, 1061050, 3083301, 1801675, 1142086], dtype=uint32),\n",
       " 1778525)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i,neighbors[i],len(total_patch_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ground_truth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mground_truth\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ground_truth' is not defined"
     ]
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yhre-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
